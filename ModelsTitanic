############################################ Hello May pal From Coursera ###############################################
#################### I did that, in Spyder noteBook, y used the dataset Call titanic, and used All Algorits Als ########

##############
##############LogisticRegression 
############## #Machine Vector Sopport KNeighborsClassifier  #Vecinos mas cercanos.
##############sklearn.model_selection import train_test_split
############

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression  #Regresion Logistica
from sklearn.svm import SVC #Maquinas de Soporte Vectorial
from sklearn.neighbors import KNeighborsClassifier  #Vecinos mas cercanos.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

dt=pd.read_csv(r"C:\Practicas\MachineLearning\Bases\titanic4.csv", sep =";")

dt.columns
dt.shape

dt.head
dt.sample(5)
#vamos a contar las columnas que tengan datos vacios
dt.isnull().sum()

PromedioEdad = dt["age"].mean()
PromedioFared=dt["fare"].mean()
print(PromedioEdad)

#vamos a llenar con el promedio la edad faltantte.
dt["age"].fillna(PromedioEdad, inplace=True)
dt["fare"].fillna(PromedioFared, inplace=True)
dt["embarked"].fillna("Q", inplace=True)

#vamos a ver que datos tiene Embarked Unicos para tomar decisiones si borramos o que
dt["embarked"].unique()  #sexo Unicos
dt["cabin"].unique()  #No usaremos Cabina
dt["boat"].unique()  #No usaremos Home Destino
dt["home.dest"].unique()  #No usaremos Home Destino
dt["body"].unique()  #No usaremos Home Destino
#vamos a ver que datos para borrar

#Vamos a reemplazar los valores de columnas
dt["sex"].replace(["female","male"],[0,1],inplace=True)
dt["embarked"].replace(["S","C","Q"],[0,1,2],inplace=True)

#vamos a crear rangos de edades para agrupar mejor las edades
#0-8,9-15,16-18,19-25,26-40,41-60,61-100 
bins=[0,8,15,18,25,40,60,100]
names=["1","2","3","4","5","6","7"]
dt["age"]=pd.cut(dt["age"], bins, labels=names)



#Seleccionamos las variables a evaluar
x = pd.DataFrame(dt, columns = ["pclass","sex","age","sibsp","parch","fare","embarked"])
y = dt["survived"]

#vamos a separar los datos entre prueba y entrenamiento
x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2)

escalar=StandardScaler()
X_train=escalar.fit_transform(x_train)
X_test=escalar.fit_transform(x_test)

#vamos a implementar los algoritmos, 
#en esta caso haremos la regresión Logistica
logreg=LogisticRegression()
logreg.fit(X_train,y_train) #las variables de entrenamiento.
y_pred=logreg.predict(X_test)  #vamos a probar los valores
print("Precisión de la regresión Logistica")
print(logreg.score(X_train, y_train))


#vamos a implementar un algoritmo de maquinas de soporte vectorial
svc=SVC()
svc.fit(X_train,y_train)
y_pred=svc.predict(X_test)
print("Precisión de las maquinas de soporte Vectorial")
print(svc.score(X_train, y_train))


#vamos a utilizar el Algoritmo Kmeans, los vecinos mas cercanos

knn =  KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred=knn.predict(X_test)
print("Precisión de los kmeans o vecinos ")
print(knn.score(X_train, y_train))


#MEDICION UTILIZANDO LOS MODELOS
ids=dt["PassangerId"]



X=escalar.fit_transform(x)

#Regresion logistica en todo el dataframe con Regresion Logistica
prediccion_logreg=logreg.predict(X)
out_logred=pd.DataFrame({'PassangerId ':ids,'survived: ':prediccion_logreg} )
print("Prediccion regresion Logistica")
print(out_logred.sample(10))


#Regresion Maquinas de Soporte en todo el dataframe con Regresion Logistica
prediccion_logreg=svc.predict(X)
out_logred=pd.DataFrame({'PassangerId ':ids,'survived: ':prediccion_logreg} )
print("Prediccion Maquinas de Soporte Vectorial")
print(out_logred.sample(10))


#Regresion Vecinos mas cercanos en todo el dataframe con Regresion Logistica
prediccion_logreg=knn.predict(X)
out_logred=pd.DataFrame({'PassangerId ':ids,'survived: ':prediccion_logreg} )
print("Prediccion Maquinas de Soporte Vectorial")
print(out_logred.sample(10))

#Todos los datos.
y_pred=prediccion_logreg
y_test=y
#vamos a calcular mas metricas del algoritmo

from sklearn.metrics import confusion_matrix

matriz=confusion_matrix(y_test,y_pred)
print("Matriz de Confusión")
print(matriz)

#vamos a probar la precision del algoritmo
from sklearn.metrics import precision_score
#Precision del modelo
precision=precision_score(y_test,y_pred)
print("Precision del Modelo ->>>", precision)

#Ahora la exactitud del modelo a predecir
from sklearn.metrics import accuracy_score
exactitud=accuracy_score(y_test,y_pred)
print("Exactitud del modelo >>>",exactitud)


#ahora vamos a calcular la sensibilidad
from sklearn.metrics import recall_score
sensibilidad=recall_score(y_test,y_pred)
print("Sensibilidad del modelo >>>",sensibilidad)

#Ahora vamos a calcular el Puntaje F1 Score
from sklearn.metrics import f1_score
puntajef1=f1_score(y_test,y_pred)
print("Puntaje F1 >>>",puntajef1)

#Ahora vamos a calcular la CURVA ROC - AUC del modelo
from sklearn.metrics import roc_auc_score
roc_auc=roc_auc_score(y_test,y_pred)
print("Curva ROC ~  AUC del modelo: >>>",roc_auc)


out_logred.to_csv(r"C:\Practicas\MachineLearning\Bases\Resultado.csv")
